import pandas as pd

import numpy as np

from sklearn import preprocessing

dataset = pd.read_csv("train.csv")

dataset.isnull()
Out[5]: 
     PassengerId  Survived  Pclass   Name  ...  Ticket   Fare  Cabin  Embarked
0          False     False   False  False  ...   False  False   True     False
1          False     False   False  False  ...   False  False  False     False
2          False     False   False  False  ...   False  False   True     False
3          False     False   False  False  ...   False  False  False     False
4          False     False   False  False  ...   False  False   True     False
..           ...       ...     ...    ...  ...     ...    ...    ...       ...
884        False     False   False  False  ...   False  False   True     False
885        False     False   False  False  ...   False  False  False     False
886        False     False   False  False  ...   False  False   True     False
887        False     False   False  False  ...   False  False  False     False
888        False     False   False  False  ...   False  False   True     False

[889 rows x 12 columns]

dataset.isnull().sum()
Out[6]: 
PassengerId      0
Survived         0
Pclass           0
Name             0
Sex              0
Age              0
SibSp            0
Parch            0
Ticket           0
Fare             0
Cabin          687
Embarked         0
dtype: int64

dataset["Cabin"]
Out[7]: 
0       NaN
1       C85
2       NaN
3      C123
4       NaN

884     NaN
885     B42
886     NaN
887    C148
888     NaN
Name: Cabin, Length: 889, dtype: object

dataset.columns
Out[8]: 
Index(['PassengerId', 'Survived', 'Pclass', 'Name', 'Sex', 'Age', 'SibSp',
       'Parch', 'Ticket', 'Fare', 'Cabin', 'Embarked'],
      dtype='object')

dataset1 = dataset.drop(['PassengerId','Name','Ticket','Cabin'], axis=1)

label_encoder = preprocessing.LabelEncoder()

dataset1 = label_encoder.fit_transform(dataset1["Embarked"])

dataset1 = dataset.drop(['PassengerId','Name','Ticket','Cabin'], axis=1)

dataset1["Embarked"] = label_encoder.fit_transform(dataset1["Embarked"])

from sklearn.model_selection import train_test_split

from sklearn.naive_bayes import GaussianNB

dataset1["Sex"] = label_encoder.fit_transform(dataset1["Sex"])

from sklearn.metrics import accuracy_score , confusion_matrix

dataset1.columns
Out[19]: 
Index(['Survived', 'Pclass', 'Sex', 'Age', 'SibSp', 'Parch', 'Fare',
       'Embarked'],
      dtype='object')

features = ['Survived', 'Pclass', 'SibSp', 'Age', 'Parch', 'Fare','Embarked']

xTrain, xTest, yTrain, yTest = train_test_split(dataset1[features], dataset1["Sex"], test_size=0.25)

clf = BernoulliNB()

y_pred = clf.fit(xTrain, yTrain).predict(xTest)

accuracy_score(yTest, y_pred, normalize=True)
Out[45]: 0.7982062780269058

confusion_matrix(yTest, y_pred)
Out[46]: 
array([[ 59,  18],
       [ 27, 119]], dtype=int64)

While training and testing the model with Gender as a dependent variable we the highest score of 79% which is higher than embarked(65%), Pclass(56%), SibSp(68%), Survived(76%)